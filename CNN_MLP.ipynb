{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:11:22.031506Z",
     "start_time": "2025-12-21T14:11:22.026502Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import itertools\n",
    "import os"
   ],
   "id": "8e806c00a1cf9464",
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:35:35.042396Z",
     "start_time": "2025-12-21T14:35:35.039161Z"
    }
   },
   "source": [
    "# è¨­å®šå…¨åŸŸåƒæ•¸\n",
    "K_VALUE = 6              # ä¿æŒ K=6 æ•æ‰é«˜éšç‰¹å¾µ\n",
    "MAX_SEQ_LEN = 750        # æå‡é•·åº¦\n",
    "BATCH_SIZE = 64          # æå‡ Batch Size ç©©å®šæ¢¯åº¦\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "5833055e15d16442",
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:11:22.099395Z",
     "start_time": "2025-12-21T14:11:22.093565Z"
    }
   },
   "source": [
    "# --- æ­¥é©Ÿ 1: è³‡æ–™è®€å–èˆ‡æ¬Šé‡å„ªåŒ– ---\n",
    "def load_and_preprocess():\n",
    "    train_df = pd.read_csv('dataset/train.csv')\n",
    "    val_df = pd.read_csv('dataset/validation.csv')\n",
    "    test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "    def clean_seq(seq): return seq.strip('<>').upper()\n",
    "    for df in [train_df, val_df, test_df]:\n",
    "        df['seq_clean'] = df['NucleotideSequence'].apply(clean_seq)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    train_df['label'] = le.fit_transform(train_df['GeneType'])\n",
    "    val_df['label'] = le.transform(val_df['GeneType'])\n",
    "    test_df['label'] = le.transform(test_df['GeneType'])\n",
    "\n",
    "    # æ¬Šé‡ä¿®æ­£ï¼šä½¿ç”¨å¹³æ–¹æ ¹å€’æ•¸å¹³æ»‘åŒ–ï¼Œé˜²æ­¢éåº¦è£œå„Ÿå°é¡åˆ¥\n",
    "    counts = train_df['label'].value_counts().sort_index().values\n",
    "    weights = torch.FloatTensor(1.0 / np.sqrt(counts + 1)).to(DEVICE)\n",
    "\n",
    "    # é©—è­‰ 1: æ¨™ç±¤æ˜ å°„èˆ‡å¹³æ»‘æ¬Šé‡è¨ˆç®—æˆåŠŸã€‚\n",
    "    print(f\"âœ… è³‡æ–™è¼‰å…¥å®Œæˆã€‚é¡åˆ¥æ¬Šé‡å·²å¹³æ»‘è™•ç†ã€‚\")\n",
    "    return train_df, val_df, test_df, le, weights"
   ],
   "id": "4a32d14e5a30c5e2",
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:11:22.127665Z",
     "start_time": "2025-12-21T14:11:22.118896Z"
    }
   },
   "source": [
    "# --- æ­¥é©Ÿ 2: ç‰¹å¾µå·¥ç¨‹ (K-mer Vectorizer) ---\n",
    "def get_vectorizer():\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    vocab = [''.join(p) for p in itertools.product(bases, repeat=K_VALUE)]\n",
    "    return CountVectorizer(vocabulary=vocab)\n",
    "\n",
    "class GenomicDataset(Dataset):\n",
    "    def __init__(self, df, cv, max_len=750):\n",
    "        self.labels = df['label'].values\n",
    "        self.seqs = df['seq_clean'].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # K-mer æå–\n",
    "        kmers_list = [' '.join([s[i:i+K_VALUE] for i in range(len(s)-K_VALUE+1)]) for s in self.seqs]\n",
    "        self.kmer_features = cv.transform(kmers_list).toarray().astype(np.float32)\n",
    "        self.char_map = {'A': 1, 'C': 2, 'G': 3, 'T': 4}\n",
    "\n",
    "    def __len__(self): return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seqs[idx]\n",
    "        encoded = [self.char_map.get(b, 0) for b in seq[:self.max_len]]\n",
    "        padded = encoded + [0] * (self.max_len - len(encoded))\n",
    "        return {\n",
    "            'seq': torch.LongTensor(padded),\n",
    "            'kmer': torch.FloatTensor(self.kmer_features[idx]),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ],
   "id": "3927aca8d1d8cf64",
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:11:22.156063Z",
     "start_time": "2025-12-21T14:11:22.146651Z"
    }
   },
   "source": [
    "# --- æ­¥é©Ÿ 3: å¤šå°ºåº¦ CNN + MLP æ¨¡å‹ ---\n",
    "class AdvancedDNAHybridModel(nn.Module):\n",
    "    def __init__(self, num_classes, kmer_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(5, 64, padding_idx=0)\n",
    "\n",
    "        # å¤šå°ºåº¦å·ç©åˆ†æ”¯\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv1d(64, 64, kernel_size=7, padding=3)\n",
    "        self.conv15 = nn.Conv1d(64, 64, kernel_size=15, padding=7)\n",
    "\n",
    "        self.bn_cnn = nn.BatchNorm1d(192) # 64 * 3\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # K-mer åˆ†æ”¯ (å¼·åŒ–å±¤)\n",
    "        self.kmer_mlp = nn.Sequential(\n",
    "            nn.Linear(kmer_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(192 + 512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, seq, kmer):\n",
    "        x_seq = self.embedding(seq).transpose(1, 2)\n",
    "\n",
    "        # æå–ä¸åŒå°ºåº¦çš„å±€éƒ¨ç‰¹å¾µ\n",
    "        c3 = torch.relu(self.conv3(x_seq))\n",
    "        c7 = torch.relu(self.conv7(x_seq))\n",
    "        c15 = torch.relu(self.conv15(x_seq))\n",
    "\n",
    "        cnn_feat = torch.cat([c3, c7, c15], dim=1)\n",
    "        cnn_feat = self.pool(self.bn_cnn(cnn_feat)).squeeze(-1)\n",
    "\n",
    "        x_kmer = self.kmer_mlp(kmer)\n",
    "\n",
    "        combined = torch.cat((cnn_feat, x_kmer), dim=1)\n",
    "        return self.classifier(combined)"
   ],
   "id": "60d8105ea6c3266",
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:35:08.588941Z",
     "start_time": "2025-12-21T14:35:08.577873Z"
    }
   },
   "source": [
    "# --- æ­¥é©Ÿ 4: è¨“ç·´èˆ‡è©•ä¼°æµç¨‹ ---\n",
    "def run_pipeline():\n",
    "    train_df, val_df, test_df, le, class_weights = load_and_preprocess()\n",
    "    cv = get_vectorizer()\n",
    "\n",
    "    train_ds = GenomicDataset(train_df, cv, MAX_SEQ_LEN)\n",
    "    val_ds = GenomicDataset(val_df, cv, MAX_SEQ_LEN)\n",
    "    test_ds = GenomicDataset(test_df, cv, MAX_SEQ_LEN)\n",
    "\n",
    "    # ä¿®æ”¹é‡é»ï¼šåŠ å…¥ drop_last=True\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=True  # é˜²æ­¢æœ€å¾Œä¸€å€‹ batch åªæœ‰ 1 å€‹æ¨£æœ¬å°è‡´ BatchNorm å´©æ½°\n",
    "    )\n",
    "\n",
    "    # é©—è­‰é›†èˆ‡æ¸¬è©¦é›†é€šå¸¸ä¸éœ€ drop_lastï¼Œå› ç‚ºæˆ‘å€‘æœƒå‘¼å« model.eval()\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = AdvancedDNAHybridModel(len(le.classes_), 4**K_VALUE).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "    # é©—è­‰ 2: æ¨¡å‹çµæ§‹èˆ‡ç¶­åº¦æª¢æŸ¥é€šéã€‚é–‹å§‹è¨“ç·´...\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch['seq'].to(DEVICE), batch['kmer'].to(DEVICE))\n",
    "            loss = criterion(out, batch['label'].to(DEVICE))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                out = model(batch['seq'].to(DEVICE), batch['kmer'].to(DEVICE))\n",
    "                val_loss += criterion(out, batch['label'].to(DEVICE)).item()\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "    # é©—è­‰ 3: è¨“ç·´å®Œæˆã€‚æ­£åœ¨è¨ˆç®—æ¸¬è©¦é›†æŒ‡æ¨™...\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            logits = model(batch['seq'].to(DEVICE), batch['kmer'].to(DEVICE))\n",
    "            all_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "\n",
    "    # è¼¸å‡ºæœ€çµ‚å ±è¡¨\n",
    "    print(f\"\\nğŸš€ æå‡å¾Œçš„æ¸¬è©¦é›†æº–ç¢ºç‡: {accuracy_score(test_df['label'], all_preds):.4f}\")\n",
    "    print(classification_report(test_df['label'], all_preds, target_names=le.classes_))\n",
    "\n",
    "    # é©—è­‰ 4: æˆåŠŸç”¢å‡º results.csvã€‚\n",
    "    results = pd.DataFrame({'id': test_df['NCBIGeneID'], 'label': le.inverse_transform(all_preds)})\n",
    "    results.to_csv('results.csv', index=False)\n",
    "    torch.save(model, 'full_model_dna.pt')"
   ],
   "id": "7d14a754ac3b0143",
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T14:35:53.547989Z",
     "start_time": "2025-12-21T14:35:38.902413Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ],
   "id": "8d3269d6e25e8ab3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è³‡æ–™è¼‰å…¥å®Œæˆã€‚é¡åˆ¥æ¬Šé‡å·²å¹³æ»‘è™•ç†ã€‚\n",
      "Epoch 1/1 | Train Loss: 1.4593 | Val Loss: 1.1974\n",
      "\n",
      "ğŸš€ æå‡å¾Œçš„æ¸¬è©¦é›†æº–ç¢ºç‡: 0.6713\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "BIOLOGICAL_REGION       0.80      0.85      0.82      2651\n",
      "            OTHER       0.00      0.00      0.00       133\n",
      "   PROTEIN_CODING       0.20      0.57      0.29       184\n",
      "           PSEUDO       0.79      0.65      0.71      3800\n",
      "            ncRNA       0.38      0.64      0.48       894\n",
      "             rRNA       0.76      0.90      0.83        72\n",
      "            scRNA       0.00      0.00      0.00         1\n",
      "            snRNA       0.00      0.00      0.00        38\n",
      "           snoRNA       0.46      0.31      0.37       405\n",
      "             tRNA       0.00      0.00      0.00       148\n",
      "\n",
      "         accuracy                           0.67      8326\n",
      "        macro avg       0.34      0.39      0.35      8326\n",
      "     weighted avg       0.69      0.67      0.67      8326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jay07\\miniconda3\\envs\\ML_final\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\jay07\\miniconda3\\envs\\ML_final\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\jay07\\miniconda3\\envs\\ML_final\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 76
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
